{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAS Methodology Deep Dive\n",
    "\n",
    "This notebook explores the **Rademacher Anti-Serum (RAS)** methodology in detail, explaining:\n",
    "1. Why traditional backtesting can be misleading\n",
    "2. What RAS measures and how it works\n",
    "3. The components of the RAS adjustment\n",
    "4. How to interpret RAS results\n",
    "5. Practical implications for strategy evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem: Data Snooping Bias\n",
    "\n",
    "When backtesting trading strategies, we face several sources of bias:\n",
    "\n",
    "1. **Estimation Error**: Limited historical data gives noisy estimates\n",
    "2. **Data Snooping**: Testing multiple strategies inflates the chance of finding one that \"worked\" by luck\n",
    "3. **Overfitting**: Complex strategies may fit noise rather than signal\n",
    "\n",
    "The **Sharpe ratio** is a common performance measure:\n",
    "\n",
    "$$\\text{Sharpe Ratio} = \\frac{\\text{Mean Return}}{\\text{Standard Deviation}}$$\n",
    "\n",
    "But the *empirical* Sharpe ratio from a backtest is an **overestimate** of the true Sharpe ratio we can expect going forward.\n",
    "\n",
    "RAS provides a **statistically rigorous lower bound** on the true Sharpe ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rademacher_backtest as rbt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "prices = pd.read_csv('data/sample_prices.csv', index_col='date', parse_dates=True)\n",
    "loader = rbt.DataFrameLoader(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a Simple Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backtest on 60/40 portfolio\n",
    "result = rbt.backtest(\n",
    "    portfolio={'SPY': 0.60, 'AGG': 0.40},\n",
    "    loader=loader,\n",
    "    start_date='2015-01-01',\n",
    "    end_date='2023-12-31',\n",
    ")\n",
    "\n",
    "print(f\"Backtest period: {len(result.daily_returns)} days\")\n",
    "print(f\"Mean daily return: {result.daily_returns.mean():.6f}\")\n",
    "print(f\"Daily volatility: {result.daily_returns.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAS Analysis: The Components\n",
    "\n",
    "RAS adjusts the empirical Sharpe ratio with two penalties:\n",
    "\n",
    "$$\\text{RAS-Adjusted Sharpe} = \\text{Empirical Sharpe} - \\text{Estimation Haircut} - \\text{Complexity Haircut}$$\n",
    "\n",
    "Let's break down each component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform RAS analysis\n",
    "ras = rbt.analyze_ras(\n",
    "    returns=result.daily_returns,\n",
    "    confidence=0.99,\n",
    "    n_strategies=1,\n",
    ")\n",
    "\n",
    "# Display raw bounds (daily)\n",
    "print(\"ðŸ“Š RAS Components (Daily):\")\n",
    "print(f\"  Empirical Sharpe: {ras.empirical_sharpe:.6f}\")\n",
    "print(f\"  Estimation Haircut: {ras.estimation_haircut:.6f}\")\n",
    "print(f\"  Complexity Haircut: {ras.complexity_haircut:.6f}\")\n",
    "print(f\"  Total Haircut: {ras.total_haircut:.6f}\")\n",
    "print(f\"  Adjusted Sharpe: {ras.adjusted_sharpe:.6f}\")\n",
    "\n",
    "print(\"\\nðŸ“Š RAS Components (Annualized):\")\n",
    "print(f\"  Empirical Sharpe: {ras.empirical_sharpe_annualized:.4f}\")\n",
    "print(f\"  Estimation Haircut: {ras.estimation_haircut_annualized:.4f}\")\n",
    "print(f\"  Complexity Haircut: {ras.complexity_haircut_annualized:.4f}\")\n",
    "print(f\"  Total Haircut: {ras.total_haircut_annualized:.4f}\")\n",
    "print(f\"  Adjusted Sharpe: {ras.adjusted_sharpe_annualized:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Estimation Haircut\n",
    "\n",
    "This accounts for **sampling error** from having finite data. Even a truly unprofitable strategy can appear profitable in a backtest due to random luck.\n",
    "\n",
    "The estimation haircut is roughly:\n",
    "\n",
    "$$\\text{Estimation Haircut} \\approx \\frac{1}{\\sqrt{T}}$$\n",
    "\n",
    "where $T$ is the number of observations. More data = smaller haircut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how estimation haircut decreases with more data\n",
    "sample_sizes = np.arange(50, 2500, 50)\n",
    "estimation_haircuts = []\n",
    "\n",
    "for T in sample_sizes:\n",
    "    # Use first T days\n",
    "    returns_subset = result.daily_returns.iloc[:T]\n",
    "    ras_subset = rbt.analyze_ras(returns_subset, confidence=0.99)\n",
    "    estimation_haircuts.append(ras_subset.estimation_haircut_annualized)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sample_sizes, estimation_haircuts, linewidth=2)\n",
    "plt.xlabel('Sample Size (trading days)', fontsize=12)\n",
    "plt.ylabel('Estimation Haircut (Annualized)', fontsize=12)\n",
    "plt.title('Estimation Haircut vs Sample Size\\n(Decreases as ~1/âˆšT)', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nWith {len(result.daily_returns)} days of data:\")\n",
    "print(f\"  Estimation haircut â‰ˆ {ras.estimation_haircut_annualized:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Complexity Haircut\n",
    "\n",
    "This accounts for **model complexity** and **data snooping**. If you tested many strategies and picked the best one, the winner likely benefited from luck.\n",
    "\n",
    "The complexity haircut depends on:\n",
    "- **Rademacher complexity**: How flexible your strategy space is\n",
    "- **Number of strategies tested**: More tests = higher penalty\n",
    "\n",
    "RAS estimates this using Monte Carlo simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how complexity haircut increases with number of strategies tested\n",
    "n_strategies_tested = [1, 2, 5, 10, 20, 50, 100]\n",
    "complexity_haircuts = []\n",
    "\n",
    "for N in n_strategies_tested:\n",
    "    ras_multi = rbt.analyze_ras(result.daily_returns, confidence=0.99, n_strategies=N)\n",
    "    complexity_haircuts.append(ras_multi.complexity_haircut_annualized)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_strategies_tested, complexity_haircuts, marker='o', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Strategies Tested', fontsize=12)\n",
    "plt.ylabel('Complexity Haircut (Annualized)', fontsize=12)\n",
    "plt.title('Complexity Haircut vs Number of Strategies\\n(Multiple Testing Penalty)', \n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nComplexity penalty for testing different numbers of strategies:\")\n",
    "for N, haircut in zip(n_strategies_tested, complexity_haircuts):\n",
    "    print(f\"  {N:3d} strategies: +{haircut:.4f} haircut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Significance Test\n",
    "\n",
    "RAS provides a formal test:\n",
    "\n",
    "**Null Hypothesis**: The strategy has zero or negative Sharpe ratio\n",
    "\n",
    "**Decision Rule**: \n",
    "- If RAS-adjusted Sharpe > 0, we **reject the null** at the specified confidence level\n",
    "- The strategy is **statistically positive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ”¬ Statistical Test Results:\")\n",
    "print(f\"  Confidence Level: {ras.confidence_level:.0f}%\")\n",
    "print(f\"  Empirical Sharpe: {ras.empirical_sharpe_annualized:.4f}\")\n",
    "print(f\"  RAS-Adjusted Sharpe: {ras.adjusted_sharpe_annualized:.4f}\")\n",
    "print(f\"  Statistically Positive: {'YES âœ…' if ras.is_statistically_positive else 'NO âŒ'}\")\n",
    "\n",
    "print(f\"\\n{ras.interpretation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Haircut Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create waterfall chart showing haircut breakdown\n",
    "components = [\n",
    "    ('Empirical\\nSharpe', ras.empirical_sharpe_annualized),\n",
    "    ('Estimation\\nHaircut', -ras.estimation_haircut_annualized),\n",
    "    ('Complexity\\nHaircut', -ras.complexity_haircut_annualized),\n",
    "    ('RAS-Adjusted\\nSharpe', ras.adjusted_sharpe_annualized),\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Bar positions\n",
    "x = np.arange(len(components))\n",
    "values = [c[1] for c in components]\n",
    "labels = [c[0] for c in components]\n",
    "\n",
    "# Colors\n",
    "colors = ['#2ecc71', '#e74c3c', '#e74c3c', '#3498db']\n",
    "\n",
    "bars = ax.bar(x, values, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, val) in enumerate(zip(bars, values)):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{val:.4f}',\n",
    "            ha='center', va='bottom' if val > 0 else 'top',\n",
    "            fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, fontsize=11)\n",
    "ax.set_ylabel('Sharpe Ratio (Annualized)', fontsize=12)\n",
    "ax.set_title('RAS Haircut Decomposition', fontsize=14, fontweight='bold')\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Confidence Level\n",
    "\n",
    "Higher confidence levels demand more conservative bounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_levels = [0.90, 0.95, 0.99, 0.999]\n",
    "adjusted_sharpes = []\n",
    "\n",
    "for conf in confidence_levels:\n",
    "    ras_conf = rbt.analyze_ras(result.daily_returns, confidence=conf)\n",
    "    adjusted_sharpes.append(ras_conf.adjusted_sharpe_annualized)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([c * 100 for c in confidence_levels], adjusted_sharpes, \n",
    "         marker='o', linewidth=2, markersize=10)\n",
    "plt.axhline(y=ras.empirical_sharpe_annualized, color='green', \n",
    "           linestyle='--', label='Empirical Sharpe', linewidth=2)\n",
    "plt.xlabel('Confidence Level (%)', fontsize=12)\n",
    "plt.ylabel('RAS-Adjusted Sharpe (Annualized)', fontsize=12)\n",
    "plt.title('Effect of Confidence Level on RAS Adjustment', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRAS-Adjusted Sharpe at different confidence levels:\")\n",
    "for conf, adj_sharpe in zip(confidence_levels, adjusted_sharpes):\n",
    "    print(f\"  {conf*100:5.1f}% confidence: {adj_sharpe:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Implications\n",
    "\n",
    "### 1. More Data = Better\n",
    "The estimation haircut decreases with sample size. Longer backtests provide tighter bounds.\n",
    "\n",
    "### 2. Testing Multiple Strategies is Costly\n",
    "Each additional strategy tested increases the complexity haircut. This is the **multiple testing problem**.\n",
    "\n",
    "### 3. Simple Strategies Preferred\n",
    "Complex strategies with many parameters have higher Rademacher complexity, leading to larger haircuts.\n",
    "\n",
    "### 4. Out-of-Sample is Still Important\n",
    "RAS provides a statistical bound, but true out-of-sample testing remains the gold standard.\n",
    "\n",
    "### 5. Use for Go/No-Go Decisions\n",
    "If RAS-adjusted Sharpe â‰¤ 0, the strategy is **not statistically distinguishable from zero**. Don't trade it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The Rademacher Anti-Serum (RAS) methodology provides:\n",
    "\n",
    "1. **Rigorous statistical bounds** on the Sharpe ratio\n",
    "2. **Correction for data snooping** and multiple testing\n",
    "3. **Penalty for model complexity** and overfitting\n",
    "4. **Clear decision rule** for strategy viability\n",
    "\n",
    "Key formula:\n",
    "\n",
    "$$\\text{RAS-Adjusted Sharpe} = \\text{Empirical Sharpe} - \\frac{\\text{Estimation}}{\\sqrt{T}} - \\text{Complexity}(N, \\mathcal{F})$$\n",
    "\n",
    "Where:\n",
    "- $T$ = sample size\n",
    "- $N$ = number of strategies tested\n",
    "- $\\mathcal{F}$ = strategy complexity\n",
    "\n",
    "**Bottom Line**: If your RAS-adjusted Sharpe ratio is positive, you have **statistically significant evidence** of outperformance, accounting for all the ways backtest results can be misleading.\n",
    "\n",
    "## References\n",
    "\n",
    "- Bailey & LÃ³pez de Prado (2012): \"The Sharpe Ratio Efficient Frontier\"\n",
    "- Bailey, Borwein, LÃ³pez de Prado, & Zhu (2014): \"Pseudomathematics and Financial Charlatanism: The Effects of Backtest Overfitting on Out-of-Sample Performance\"\n",
    "- LÃ³pez de Prado (2018): *Advances in Financial Machine Learning*, Chapter 8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
